#!/usr/bin/env python3
from flask import Flask, request, jsonify, render_template_string, render_template
from flask_cors import CORS
import io
import sys
import json
import os
import numpy as np
import sqlite3
import threading
import time
import socket
import re
from datetime import datetime, timedelta
from contextlib import redirect_stdout, redirect_stderr

# å°è¯•å¯¼å…¥paramikoï¼Œå¦‚æœæ²¡æœ‰å®‰è£…åˆ™æç¤º
try:
    import paramiko
    PARAMIKO_AVAILABLE = True
except ImportError:
    PARAMIKO_AVAILABLE = False
    print("âš ï¸  è­¦å‘Š: paramikoåº“æœªå®‰è£…ï¼ŒSSHè¿æ¥åŠŸèƒ½å°†è¢«ç¦ç”¨")
    print("   å®‰è£…å‘½ä»¤: pip install paramiko")

class HistoricalDataPersistence:
    """å†å²æ•°æ®æŒä¹…åŒ–ç®¡ç†ç±»"""

    def __init__(self, data_dir='historical_data'):
        self.data_dir = data_dir
        self.ensure_data_dir()

    def ensure_data_dir(self):
        """ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)
            print(f"ğŸ“ åˆ›å»ºå†å²æ•°æ®ç›®å½•: {self.data_dir}")

    def get_file_path(self, server_id, metric_type):
        """è·å–æŒ‡å®šæœåŠ¡å™¨å’ŒæŒ‡æ ‡ç±»å‹çš„æ–‡ä»¶è·¯å¾„"""
        filename = f"{server_id}_{metric_type}.txt"
        return os.path.join(self.data_dir, filename)

    def save_historical_data(self, server_id, historical_data):
        """ä¿å­˜å†å²æ•°æ®åˆ°æ–‡ä»¶ï¼ˆè¿½åŠ æ¨¡å¼ï¼‰"""
        try:
            # ä¿å­˜CPUæ•°æ®
            self._append_metric_data(server_id, 'cpu', historical_data['timestamps'], historical_data['cpu'])

            # ä¿å­˜å†…å­˜æ•°æ®
            self._append_metric_data(server_id, 'memory', historical_data['timestamps'], historical_data['memory'])

            # ä¿å­˜ç£ç›˜IOæ•°æ®
            self._append_disk_io_data(server_id, historical_data['timestamps'],
                                    historical_data['disk_read'], historical_data['disk_write'])

            # ä¿å­˜ç½‘ç»œæ•°æ®
            self._append_network_data(server_id, historical_data['timestamps'],
                                    historical_data['network_sent'], historical_data['network_recv'])

            print(f"ğŸ’¾ å†å²æ•°æ®å·²è¿½åŠ ä¿å­˜åˆ°æ–‡ä»¶: {server_id}")

        except Exception as e:
            print(f"âŒ ä¿å­˜å†å²æ•°æ®å¤±è´¥: {e}")

    def _append_metric_data(self, server_id, metric_type, timestamps, values):
        """è¿½åŠ å•ä¸€æŒ‡æ ‡æ•°æ®ï¼ˆCPUæˆ–å†…å­˜ï¼‰"""
        file_path = self.get_file_path(server_id, metric_type)

        # åŠ è½½ç°æœ‰æ•°æ®
        existing_data = {'timestamps': [], 'values': []}
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
            except:
                pass  # å¦‚æœæ–‡ä»¶æŸåï¼Œä»ç©ºæ•°æ®å¼€å§‹

        # åˆå¹¶æ•°æ®ï¼ˆé¿å…é‡å¤æ—¶é—´æˆ³ï¼‰
        existing_timestamps = set(existing_data.get('timestamps', []))
        for i, timestamp in enumerate(timestamps):
            if timestamp not in existing_timestamps:
                existing_data['timestamps'].append(timestamp)
                existing_data['values'].append(values[i])

        # é™åˆ¶æ•°æ®ç‚¹æ•°é‡ï¼ˆä¿ç•™æœ€æ–°çš„1000ä¸ªæ•°æ®ç‚¹ï¼‰
        max_points = 1000
        if len(existing_data['timestamps']) > max_points:
            existing_data['timestamps'] = existing_data['timestamps'][-max_points:]
            existing_data['values'] = existing_data['values'][-max_points:]

        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=2)

    def _append_disk_io_data(self, server_id, timestamps, disk_read, disk_write):
        """è¿½åŠ ç£ç›˜IOæ•°æ®"""
        file_path = self.get_file_path(server_id, 'disk_io')

        # åŠ è½½ç°æœ‰æ•°æ®
        existing_data = {'timestamps': [], 'disk_read': [], 'disk_write': []}
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
            except:
                pass

        # åˆå¹¶æ•°æ®
        existing_timestamps = set(existing_data.get('timestamps', []))
        for i, timestamp in enumerate(timestamps):
            if timestamp not in existing_timestamps:
                existing_data['timestamps'].append(timestamp)
                existing_data['disk_read'].append(disk_read[i])
                existing_data['disk_write'].append(disk_write[i])

        # é™åˆ¶æ•°æ®ç‚¹æ•°é‡
        max_points = 1000
        if len(existing_data['timestamps']) > max_points:
            existing_data['timestamps'] = existing_data['timestamps'][-max_points:]
            existing_data['disk_read'] = existing_data['disk_read'][-max_points:]
            existing_data['disk_write'] = existing_data['disk_write'][-max_points:]

        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=2)

    def _append_network_data(self, server_id, timestamps, network_sent, network_recv):
        """è¿½åŠ ç½‘ç»œæ•°æ®"""
        file_path = self.get_file_path(server_id, 'network')

        # åŠ è½½ç°æœ‰æ•°æ®
        existing_data = {'timestamps': [], 'network_sent': [], 'network_recv': []}
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
            except:
                pass

        # åˆå¹¶æ•°æ®
        existing_timestamps = set(existing_data.get('timestamps', []))
        for i, timestamp in enumerate(timestamps):
            if timestamp not in existing_timestamps:
                existing_data['timestamps'].append(timestamp)
                existing_data['network_sent'].append(network_sent[i])
                existing_data['network_recv'].append(network_recv[i])

        # é™åˆ¶æ•°æ®ç‚¹æ•°é‡
        max_points = 1000
        if len(existing_data['timestamps']) > max_points:
            existing_data['timestamps'] = existing_data['timestamps'][-max_points:]
            existing_data['network_sent'] = existing_data['network_sent'][-max_points:]
            existing_data['network_recv'] = existing_data['network_recv'][-max_points:]

        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=2)

    def append_realtime_data(self, server_id, timestamp, cpu, memory, disk_read, disk_write, network_sent, network_recv):
        """è¿½åŠ å•ä¸ªå®æ—¶æ•°æ®ç‚¹"""
        try:
            # è¿½åŠ CPUæ•°æ®
            self._append_metric_data(server_id, 'cpu', [timestamp], [cpu])

            # è¿½åŠ å†…å­˜æ•°æ®
            self._append_metric_data(server_id, 'memory', [timestamp], [memory])

            # è¿½åŠ ç£ç›˜IOæ•°æ®
            self._append_disk_io_data(server_id, [timestamp], [disk_read], [disk_write])

            # è¿½åŠ ç½‘ç»œæ•°æ®
            self._append_network_data(server_id, [timestamp], [network_sent], [network_recv])

            print(f"ğŸ“Š å®æ—¶æ•°æ®å·²è¿½åŠ : {server_id} @ {timestamp}")

        except Exception as e:
            print(f"âŒ è¿½åŠ å®æ—¶æ•°æ®å¤±è´¥: {e}")

    def load_historical_data(self, server_id):
        """ä»æ–‡ä»¶åŠ è½½å†å²æ•°æ®"""
        try:
            result = {
                'timestamps': [],
                'cpu': [],
                'memory': [],
                'disk_read': [],
                'disk_write': [],
                'network_sent': [],
                'network_recv': []
            }

            # åŠ è½½CPUæ•°æ®
            cpu_file = self.get_file_path(server_id, 'cpu')
            if os.path.exists(cpu_file):
                with open(cpu_file, 'r', encoding='utf-8') as f:
                    cpu_data = json.load(f)
                    result['timestamps'] = cpu_data.get('timestamps', [])
                    result['cpu'] = cpu_data.get('values', [])

            # åŠ è½½å†…å­˜æ•°æ®
            memory_file = self.get_file_path(server_id, 'memory')
            if os.path.exists(memory_file):
                with open(memory_file, 'r', encoding='utf-8') as f:
                    memory_data = json.load(f)
                    if not result['timestamps']:  # å¦‚æœCPUæ•°æ®æ²¡æœ‰æ—¶é—´æˆ³ï¼Œä½¿ç”¨å†…å­˜æ•°æ®çš„
                        result['timestamps'] = memory_data.get('timestamps', [])
                    result['memory'] = memory_data.get('values', [])

            # åŠ è½½ç£ç›˜IOæ•°æ®
            disk_file = self.get_file_path(server_id, 'disk_io')
            if os.path.exists(disk_file):
                with open(disk_file, 'r', encoding='utf-8') as f:
                    disk_data = json.load(f)
                    if not result['timestamps']:
                        result['timestamps'] = disk_data.get('timestamps', [])
                    result['disk_read'] = disk_data.get('disk_read', [])
                    result['disk_write'] = disk_data.get('disk_write', [])

            # åŠ è½½ç½‘ç»œæ•°æ®
            network_file = self.get_file_path(server_id, 'network')
            if os.path.exists(network_file):
                with open(network_file, 'r', encoding='utf-8') as f:
                    network_data = json.load(f)
                    if not result['timestamps']:
                        result['timestamps'] = network_data.get('timestamps', [])
                    result['network_sent'] = network_data.get('network_sent', [])
                    result['network_recv'] = network_data.get('network_recv', [])

            if result['timestamps']:
                print(f"ğŸ“– ä»æ–‡ä»¶åŠ è½½å†å²æ•°æ®: {server_id}, {len(result['timestamps'])}ä¸ªæ•°æ®ç‚¹")
                return result
            else:
                print(f"ğŸ“– æœªæ‰¾åˆ°å†å²æ•°æ®æ–‡ä»¶: {server_id}")
                return None

        except Exception as e:
            print(f"âŒ åŠ è½½å†å²æ•°æ®å¤±è´¥: {e}")
            return None

app = Flask(__name__, static_folder='dist/static', template_folder='dist')
CORS(app)

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')

@app.route('/code-executor')
def code_executor():
    """ä»£ç æ‰§è¡Œå™¨é¡µé¢"""
    return render_template('code_executor.html')

@app.route('/execute-script', methods=['POST'])
def execute_script():
    try:
        data = request.get_json()
        code = data.get('code', '')
        
        if not code.strip():
            return jsonify({'success': False, 'error': 'ä»£ç å†…å®¹ä¸èƒ½ä¸ºç©º'})
        
        # # ç®€å•çš„å®‰å…¨æ£€æŸ¥
        # dangerous = ['import os', 'import sys', 'open(', 'file(', 'exec(', 'eval(']
        # for danger in dangerous:
        #     if danger in code.lower():
        #         return jsonify({'success': False, 'error': f'ä¸å…è®¸ä½¿ç”¨: {danger}'})
        
        # æ‰§è¡Œä»£ç 
        stdout_buffer = io.StringIO()
        stderr_buffer = io.StringIO()
        
        try:
            with redirect_stdout(stdout_buffer), redirect_stderr(stderr_buffer):
                exec(code)
            
            return jsonify({
                'success': True,
                'output': stdout_buffer.getvalue(),
                'error': stderr_buffer.getvalue()
            })
        except Exception as e:
            return jsonify({
                'success': False,
                'output': stdout_buffer.getvalue(),
                'error': str(e)
            })
    except Exception as e:
        return jsonify({'success': False, 'error': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'})

@app.route('/api/health', methods=['GET'])
def health():
    return jsonify({'status': 'healthy'})

# æ€§èƒ½ç›‘æ§æ•°æ®åˆ†æç±»
class PerformanceAnalyzer:
    def __init__(self):
        self.analysis_patterns = {
            'cpu_high_usage': {'threshold': 80, 'severity': 'high'},
            'cpu_sustained_high': {'threshold': 60, 'duration_ratio': 0.3, 'severity': 'medium'},
            'memory_high_usage': {'threshold': 85, 'severity': 'high'},
            'memory_sustained_high': {'threshold': 70, 'duration_ratio': 0.4, 'severity': 'medium'},
            'load_high': {'severity': 'high'},
            'context_switch_high': {'threshold_per_sec': 10000, 'severity': 'medium'}
        }

    def analyze_monitoring_data(self, data):
        """åˆ†æç›‘æ§æ•°æ®ï¼Œè¯†åˆ«æ€§èƒ½ç“¶é¢ˆ"""
        analysis_result = {
            'system_info': data.get('system_info', {}),
            'monitoring_summary': data.get('monitoring_summary', {}),
            'bottlenecks': [],
            'recommendations': [],
            'performance_score': 100,
            'charts_data': self._prepare_charts_data(data)
        }

        cpu_data = data.get('cpu_data', [])
        memory_data = data.get('memory_data', [])

        if cpu_data:
            cpu_analysis = self._analyze_cpu_data(cpu_data, data['system_info'])
            analysis_result['bottlenecks'].extend(cpu_analysis['bottlenecks'])
            analysis_result['recommendations'].extend(cpu_analysis['recommendations'])
            analysis_result['performance_score'] -= cpu_analysis['score_penalty']

        if memory_data:
            memory_analysis = self._analyze_memory_data(memory_data)
            analysis_result['bottlenecks'].extend(memory_analysis['bottlenecks'])
            analysis_result['recommendations'].extend(memory_analysis['recommendations'])
            analysis_result['performance_score'] -= memory_analysis['score_penalty']

        # ç¡®ä¿æ€§èƒ½åˆ†æ•°ä¸ä½äº0
        analysis_result['performance_score'] = max(0, analysis_result['performance_score'])

        return analysis_result

    def _analyze_cpu_data(self, cpu_data, system_info):
        """åˆ†æCPUæ•°æ®"""
        bottlenecks = []
        recommendations = []
        score_penalty = 0

        cpu_usage = [item['cpu_percent_total'] for item in cpu_data]
        load_avg = [item['load_average_1min'] for item in cpu_data]
        cpu_count = system_info.get('cpu_count_logical', 1)

        # åˆ†æCPUä½¿ç”¨ç‡
        avg_cpu = np.mean(cpu_usage)
        max_cpu = np.max(cpu_usage)
        high_cpu_ratio = len([x for x in cpu_usage if x > 80]) / len(cpu_usage)

        if max_cpu > 95:
            bottlenecks.append({
                'type': 'cpu_critical',
                'severity': 'critical',
                'description': f'CPUä½¿ç”¨ç‡è¾¾åˆ°å³°å€¼ {max_cpu:.1f}%',
                'impact': 'ç³»ç»Ÿå“åº”ä¸¥é‡å»¶è¿Ÿï¼Œå¯èƒ½å‡ºç°æœåŠ¡ä¸å¯ç”¨'
            })
            recommendations.append('ç«‹å³æ£€æŸ¥CPUå¯†é›†å‹è¿›ç¨‹ï¼Œè€ƒè™‘æ‰©å®¹æˆ–ä¼˜åŒ–ç®—æ³•')
            score_penalty += 30
        elif avg_cpu > 70:
            bottlenecks.append({
                'type': 'cpu_high_average',
                'severity': 'high',
                'description': f'CPUå¹³å‡ä½¿ç”¨ç‡è¿‡é«˜ {avg_cpu:.1f}%',
                'impact': 'ç³»ç»Ÿæ•´ä½“æ€§èƒ½ä¸‹é™ï¼Œå“åº”æ—¶é—´å¢åŠ '
            })
            recommendations.append('ä¼˜åŒ–CPUå¯†é›†å‹ä»»åŠ¡ï¼Œè€ƒè™‘è´Ÿè½½å‡è¡¡æˆ–å‚ç›´æ‰©å®¹')
            score_penalty += 20

        if high_cpu_ratio > 0.3:
            bottlenecks.append({
                'type': 'cpu_sustained_high',
                'severity': 'medium',
                'description': f'{high_cpu_ratio*100:.1f}%çš„æ—¶é—´CPUä½¿ç”¨ç‡è¶…è¿‡80%',
                'impact': 'æŒç»­é«˜CPUä½¿ç”¨ç‡å½±å“ç³»ç»Ÿç¨³å®šæ€§'
            })
            recommendations.append('åˆ†æé«˜CPUä½¿ç”¨æ—¶æ®µçš„è¿›ç¨‹æ´»åŠ¨ï¼Œä¼˜åŒ–æˆ–è°ƒåº¦ä»»åŠ¡')
            score_penalty += 15

        # åˆ†æç³»ç»Ÿè´Ÿè½½
        avg_load = np.mean(load_avg)
        if avg_load > cpu_count * 2:
            bottlenecks.append({
                'type': 'load_critical',
                'severity': 'critical',
                'description': f'ç³»ç»Ÿè´Ÿè½½è¿‡é«˜ {avg_load:.2f} (CPUæ ¸å¿ƒæ•°: {cpu_count})',
                'impact': 'ç³»ç»Ÿä¸¥é‡è¿‡è½½ï¼Œä»»åŠ¡æ’é˜Ÿç­‰å¾…æ‰§è¡Œ'
            })
            recommendations.append('ç«‹å³å‡å°‘å¹¶å‘ä»»åŠ¡æ•°é‡æˆ–å¢åŠ CPUèµ„æº')
            score_penalty += 25
        elif avg_load > cpu_count:
            bottlenecks.append({
                'type': 'load_high',
                'severity': 'medium',
                'description': f'ç³»ç»Ÿè´Ÿè½½è¾ƒé«˜ {avg_load:.2f} (CPUæ ¸å¿ƒæ•°: {cpu_count})',
                'impact': 'ç³»ç»Ÿæ¥è¿‘æ»¡è´Ÿè·è¿è¡Œï¼Œæ€§èƒ½å¯èƒ½ä¸‹é™'
            })
            recommendations.append('ç›‘æ§ç³»ç»Ÿè´Ÿè½½è¶‹åŠ¿ï¼Œè€ƒè™‘ä¼˜åŒ–æˆ–æ‰©å®¹')
            score_penalty += 10

        return {
            'bottlenecks': bottlenecks,
            'recommendations': recommendations,
            'score_penalty': score_penalty
        }

    def _analyze_memory_data(self, memory_data):
        """åˆ†æå†…å­˜æ•°æ®"""
        bottlenecks = []
        recommendations = []
        score_penalty = 0

        memory_usage = [item['memory_percent'] for item in memory_data]
        swap_usage = [item['swap_percent'] for item in memory_data]

        avg_memory = np.mean(memory_usage)
        max_memory = np.max(memory_usage)
        avg_swap = np.mean(swap_usage)
        max_swap = np.max(swap_usage)

        # åˆ†æå†…å­˜ä½¿ç”¨ç‡
        if max_memory > 95:
            bottlenecks.append({
                'type': 'memory_critical',
                'severity': 'critical',
                'description': f'å†…å­˜ä½¿ç”¨ç‡è¾¾åˆ°å³°å€¼ {max_memory:.1f}%',
                'impact': 'ç³»ç»Ÿå¯èƒ½å‡ºç°OOMï¼ŒæœåŠ¡ä¸ç¨³å®š'
            })
            recommendations.append('ç«‹å³é‡Šæ”¾å†…å­˜æˆ–å¢åŠ ç‰©ç†å†…å­˜')
            score_penalty += 30
        elif avg_memory > 80:
            bottlenecks.append({
                'type': 'memory_high',
                'severity': 'high',
                'description': f'å†…å­˜å¹³å‡ä½¿ç”¨ç‡è¿‡é«˜ {avg_memory:.1f}%',
                'impact': 'å†…å­˜å‹åŠ›å¤§ï¼Œå¯èƒ½å½±å“æ€§èƒ½'
            })
            recommendations.append('ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œæ£€æŸ¥å†…å­˜æ³„æ¼ï¼Œè€ƒè™‘å¢åŠ å†…å­˜')
            score_penalty += 20

        # åˆ†æäº¤æ¢åˆ†åŒºä½¿ç”¨
        if max_swap > 50:
            bottlenecks.append({
                'type': 'swap_critical',
                'severity': 'critical',
                'description': f'äº¤æ¢åˆ†åŒºä½¿ç”¨ç‡è¿‡é«˜ {max_swap:.1f}%',
                'impact': 'é¢‘ç¹çš„ç£ç›˜äº¤æ¢ä¸¥é‡å½±å“æ€§èƒ½'
            })
            recommendations.append('ç«‹å³å¢åŠ ç‰©ç†å†…å­˜æˆ–ä¼˜åŒ–å†…å­˜ä½¿ç”¨')
            score_penalty += 25
        elif avg_swap > 10:
            bottlenecks.append({
                'type': 'swap_high',
                'severity': 'medium',
                'description': f'äº¤æ¢åˆ†åŒºå¹³å‡ä½¿ç”¨ç‡ {avg_swap:.1f}%',
                'impact': 'å­˜åœ¨å†…å­˜å‹åŠ›ï¼Œæ€§èƒ½å¯èƒ½å—å½±å“'
            })
            recommendations.append('ç›‘æ§å†…å­˜ä½¿ç”¨è¶‹åŠ¿ï¼Œè€ƒè™‘å†…å­˜ä¼˜åŒ–')
            score_penalty += 10

        return {
            'bottlenecks': bottlenecks,
            'recommendations': recommendations,
            'score_penalty': score_penalty
        }

    def _prepare_charts_data(self, data):
        """å‡†å¤‡å›¾è¡¨æ•°æ®"""
        cpu_data = data.get('cpu_data', [])
        memory_data = data.get('memory_data', [])

        charts_data = {
            'cpu_timeline': [],
            'memory_timeline': [],
            'load_timeline': [],
            'cpu_cores': []
        }

        # CPUæ—¶é—´çº¿æ•°æ®
        for item in cpu_data:
            timestamp = item['timestamp']
            charts_data['cpu_timeline'].append({
                'time': timestamp,
                'cpu_percent': item['cpu_percent_total'],
                'load_1min': item['load_average_1min']
            })

        # å†…å­˜æ—¶é—´çº¿æ•°æ®
        for item in memory_data:
            timestamp = item['timestamp']
            charts_data['memory_timeline'].append({
                'time': timestamp,
                'memory_percent': item['memory_percent'],
                'swap_percent': item['swap_percent'],
                'memory_used_gb': item['memory_used_gb']
            })

        # CPUæ ¸å¿ƒæ•°æ®ï¼ˆå–æœ€åä¸€ä¸ªæ ·æœ¬çš„æ•°æ®ï¼‰
        if cpu_data:
            last_cpu = cpu_data[-1]
            for i, usage in enumerate(last_cpu['cpu_percent_per_core']):
                charts_data['cpu_cores'].append({
                    'core': f'Core {i}',
                    'usage': usage
                })

        return charts_data

# åˆ›å»ºæ€§èƒ½åˆ†æå™¨å®ä¾‹
analyzer = PerformanceAnalyzer()

# æœåŠ¡å™¨ç›‘æ§ç³»ç»Ÿ
class ServerMonitor:
    def __init__(self):
        self.servers = {}  # å­˜å‚¨æœåŠ¡å™¨é…ç½®
        self.connections = {}  # SSHè¿æ¥æ± 
        self.monitoring_threads = {}  # ç›‘æ§çº¿ç¨‹
        self.metrics_data = {}  # ç›‘æ§æ•°æ®å­˜å‚¨
        self.historical_cache = {}  # å†å²æ•°æ®ç¼“å­˜
        self.last_update_time = {}  # ä¸Šæ¬¡æ›´æ–°æ—¶é—´
        self.persistence = HistoricalDataPersistence()  # å†å²æ•°æ®æŒä¹…åŒ–

        # ğŸš€ æ–°å¢ï¼šæ€§èƒ½ä¼˜åŒ–ç¼“å­˜
        self.performance_cache = {}  # APIå“åº”ç¼“å­˜
        self.cache_ttl = 30  # ç¼“å­˜30ç§’
        self.max_data_points = 200  # æœ€å¤šè¿”å›200ä¸ªæ•°æ®ç‚¹
        self.background_update_interval = 10  # åå°æ›´æ–°é—´éš”10ç§’
        self.background_thread = None  # åå°æ›´æ–°çº¿ç¨‹
        self.is_running = False  # åå°çº¿ç¨‹è¿è¡ŒçŠ¶æ€

        self.init_storage()
        self.start_background_update()  # å¯åŠ¨åå°æ›´æ–°

    def init_storage(self):
        """åˆå§‹åŒ–æ•°æ®å­˜å‚¨"""
        # è¿™é‡Œç®€åŒ–ä¸ºå†…å­˜å­˜å‚¨ï¼Œå®é™…é¡¹ç›®ä¸­åº”è¯¥ä½¿ç”¨æ•°æ®åº“
        self.servers = {}  # ç©ºçš„æœåŠ¡å™¨åˆ—è¡¨ï¼Œéœ€è¦ç”¨æˆ·æ‰‹åŠ¨æ·»åŠ 
        self.metrics_data = {}

    def start_background_update(self):
        """ğŸš€ å¯åŠ¨åå°æ•°æ®æ›´æ–°çº¿ç¨‹"""
        if self.background_thread and self.background_thread.is_alive():
            return

        self.is_running = True
        self.background_thread = threading.Thread(target=self._background_update_worker, daemon=True)
        self.background_thread.start()
        print("ğŸ”„ åå°æ•°æ®æ›´æ–°çº¿ç¨‹å·²å¯åŠ¨")

    def stop_background_update(self):
        """åœæ­¢åå°æ•°æ®æ›´æ–°çº¿ç¨‹"""
        self.is_running = False
        if self.background_thread:
            self.background_thread.join(timeout=5)
        print("ğŸ›‘ åå°æ•°æ®æ›´æ–°çº¿ç¨‹å·²åœæ­¢")

    def _background_update_worker(self):
        """åå°æ•°æ®æ›´æ–°å·¥ä½œçº¿ç¨‹"""
        import time

        while self.is_running:
            try:
                current_time = datetime.now()

                # ä¸ºæ¯ä¸ªæœåŠ¡å™¨æ›´æ–°ç¼“å­˜æ•°æ®
                for server_id in list(self.servers.keys()):
                    try:
                        self._update_server_cache(server_id, current_time)
                    except Exception as e:
                        print(f"âŒ æ›´æ–°æœåŠ¡å™¨ {server_id} ç¼“å­˜å¤±è´¥: {e}")

                # æ¸…ç†è¿‡æœŸç¼“å­˜
                self._cleanup_expired_cache(current_time)

                # ç­‰å¾…ä¸‹æ¬¡æ›´æ–°
                time.sleep(self.background_update_interval)

            except Exception as e:
                print(f"âŒ åå°æ›´æ–°çº¿ç¨‹é”™è¯¯: {e}")
                time.sleep(5)

    def _update_server_cache(self, server_id, current_time):
        """æ›´æ–°å•ä¸ªæœåŠ¡å™¨çš„ç¼“å­˜æ•°æ®"""
        if server_id not in self.servers:
            return

        server_config = self.servers[server_id]

        # è·å–å®æ—¶ç›‘æ§æ•°æ®
        real_metrics = self.get_real_server_metrics(server_config)
        if not real_metrics:
            return

        # æ›´æ–°ç¼“å­˜ä¸­çš„å®æ—¶æ•°æ®
        cache_key = f"{server_id}_realtime"
        self.performance_cache[cache_key] = {
            'data': real_metrics,
            'timestamp': current_time,
            'ttl': self.cache_ttl
        }

        # æ›´æ–°å†å²æ•°æ®ç¼“å­˜
        for time_range in ['1h', '6h', '24h']:
            cache_key = f"{server_id}_metrics_{time_range}"

            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
            if (cache_key not in self.performance_cache or
                (current_time - self.performance_cache[cache_key]['timestamp']).total_seconds() > self.cache_ttl):

                # ç”Ÿæˆå†å²æ•°æ®
                historical_data = self._get_cached_historical_data(server_id, time_range, real_metrics)

                self.performance_cache[cache_key] = {
                    'data': historical_data,
                    'timestamp': current_time,
                    'ttl': self.cache_ttl
                }

                print(f"ğŸ”„ å·²æ›´æ–°ç¼“å­˜: {cache_key}")

    def _cleanup_expired_cache(self, current_time):
        """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ•°æ®"""
        expired_keys = []

        for cache_key, cache_data in self.performance_cache.items():
            if (current_time - cache_data['timestamp']).total_seconds() > cache_data['ttl']:
                expired_keys.append(cache_key)

        for key in expired_keys:
            del self.performance_cache[key]

        if expired_keys:
            print(f"ğŸ§¹ æ¸…ç†äº† {len(expired_keys)} ä¸ªè¿‡æœŸç¼“å­˜")

    def _get_cached_historical_data(self, server_id, time_range, current_metrics):
        """è·å–ç¼“å­˜çš„å†å²æ•°æ®ï¼ˆé™åˆ¶æ•°æ®ç‚¹æ•°é‡ï¼‰"""
        # ä¼˜å…ˆä»æ–‡ä»¶åŠ è½½å†å²æ•°æ®
        historical_data = self.persistence.load_historical_data(server_id)

        if historical_data and historical_data.get('timestamps'):
            # é™åˆ¶æ•°æ®ç‚¹æ•°é‡
            timestamps = historical_data['timestamps']
            if len(timestamps) > self.max_data_points:
                # å‡åŒ€é‡‡æ ·ï¼Œä¿ç•™æœ€é‡è¦çš„æ•°æ®ç‚¹
                step = len(timestamps) // self.max_data_points
                indices = list(range(0, len(timestamps), step))
                if len(indices) > self.max_data_points:
                    indices = indices[:self.max_data_points]

                # ç¡®ä¿åŒ…å«æœ€æ–°çš„æ•°æ®ç‚¹
                if indices[-1] != len(timestamps) - 1:
                    indices[-1] = len(timestamps) - 1

                # é‡æ–°æ„å»ºæ•°æ®
                sampled_data = {
                    'timestamps': [timestamps[i] for i in indices],
                    'cpu_data': [historical_data.get('cpu_data', [])[i] if i < len(historical_data.get('cpu_data', [])) else 0 for i in indices],
                    'memory_data': [historical_data.get('memory_data', [])[i] if i < len(historical_data.get('memory_data', [])) else 0 for i in indices],
                    'disk_read_data': [historical_data.get('disk_read_data', [])[i] if i < len(historical_data.get('disk_read_data', [])) else 0 for i in indices],
                    'disk_write_data': [historical_data.get('disk_write_data', [])[i] if i < len(historical_data.get('disk_write_data', [])) else 0 for i in indices],
                    'network_sent': [historical_data.get('network_sent', [])[i] if i < len(historical_data.get('network_sent', [])) else 0 for i in indices],
                    'network_recv': [historical_data.get('network_recv', [])[i] if i < len(historical_data.get('network_recv', [])) else 0 for i in indices]
                }

                print(f"ğŸ“Š æ•°æ®é‡‡æ ·: {len(timestamps)} -> {len(sampled_data['timestamps'])} ä¸ªæ•°æ®ç‚¹")
                return sampled_data
            else:
                return historical_data
        else:
            # å¦‚æœæ²¡æœ‰å†å²æ•°æ®ï¼Œç”Ÿæˆæ–°çš„ï¼ˆä½†é™åˆ¶æ•°é‡ï¼‰
            return self._generate_historical_data(time_range, current_metrics, limit_points=True)

    def add_server(self, server_config):
        """æ·»åŠ æœåŠ¡å™¨é…ç½®"""
        server_id = server_config.get('id') or f"server_{len(self.servers) + 1}"
        server_config['id'] = server_id
        self.servers[server_id] = server_config
        return server_id

    def update_server(self, server_id, server_config):
        """æ›´æ–°æœåŠ¡å™¨é…ç½®"""
        if server_id in self.servers:
            server_config['id'] = server_id
            self.servers[server_id] = server_config
            return True
        return False

    def delete_server(self, server_id):
        """åˆ é™¤æœåŠ¡å™¨"""
        if server_id in self.servers:
            # åœæ­¢ç›‘æ§
            self.stop_monitoring(server_id)
            # åˆ é™¤é…ç½®
            del self.servers[server_id]
            # æ¸…ç†æ•°æ®
            if server_id in self.metrics_data:
                del self.metrics_data[server_id]
            return True
        return False

    def test_connection(self, server_config):
        """æµ‹è¯•æœåŠ¡å™¨è¿æ¥"""
        print(f"ğŸ” å¼€å§‹æµ‹è¯•è¿æ¥: {server_config.get('host')}:{server_config.get('port')}")
        print(f"   ç”¨æˆ·å: {server_config.get('username')}")
        print(f"   è®¤è¯æ–¹å¼: {server_config.get('auth_type', 'password')}")

        try:
            host = server_config['host']
            port = server_config['port']
            username = server_config['username']
            auth_type = server_config.get('auth_type', 'password')

            # éªŒè¯å¿…è¦å‚æ•°
            if not host or not port or not username:
                return False, "ç¼ºå°‘å¿…è¦çš„è¿æ¥å‚æ•°ï¼ˆä¸»æœºã€ç«¯å£ã€ç”¨æˆ·åï¼‰"

            # æ£€æŸ¥paramikoæ˜¯å¦å¯ç”¨
            if not PARAMIKO_AVAILABLE:
                return False, "SSHè¿æ¥åŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·å®‰è£…paramikoåº“: pip install paramiko"

            print(f"ğŸ“¡ æ­£åœ¨è¿æ¥åˆ° {host}:{port}...")

            # åˆ›å»ºSSHå®¢æˆ·ç«¯
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())

            # æ ¹æ®è®¤è¯æ–¹å¼è¿æ¥
            if auth_type == 'password':
                password = server_config.get('password')
                if not password:
                    return False, "å¯†ç è®¤è¯éœ€è¦æä¾›å¯†ç "

                print(f"ğŸ” ä½¿ç”¨å¯†ç è®¤è¯è¿æ¥...")
                ssh.connect(
                    hostname=host,
                    port=port,
                    username=username,
                    password=password,
                    timeout=30,  # å¢åŠ åˆ°30ç§’
                    allow_agent=False,  # ç¦ç”¨SSHä»£ç†
                    look_for_keys=False  # ç¦ç”¨è‡ªåŠ¨æŸ¥æ‰¾å¯†é’¥
                )
            elif auth_type == 'key':
                private_key_path = server_config.get('private_key_path')
                key_password = server_config.get('key_password')

                if not private_key_path:
                    return False, "å¯†é’¥è®¤è¯éœ€è¦æä¾›ç§é’¥æ–‡ä»¶è·¯å¾„"

                print(f"ğŸ”‘ ä½¿ç”¨å¯†é’¥è®¤è¯è¿æ¥: {private_key_path}")

                # å°è¯•åŠ è½½ç§é’¥
                try:
                    if private_key_path.endswith('.pem') or 'rsa' in private_key_path.lower():
                        private_key = paramiko.RSAKey.from_private_key_file(private_key_path, password=key_password)
                    else:
                        # å°è¯•è‡ªåŠ¨æ£€æµ‹å¯†é’¥ç±»å‹
                        private_key = paramiko.RSAKey.from_private_key_file(private_key_path, password=key_password)
                except:
                    try:
                        private_key = paramiko.Ed25519Key.from_private_key_file(private_key_path, password=key_password)
                    except Exception as key_error:
                        print(f"âŒ å¯†é’¥åŠ è½½å¤±è´¥: {key_error}")
                        return False, f"æ— æ³•åŠ è½½ç§é’¥æ–‡ä»¶: {private_key_path} - {str(key_error)}"

                ssh.connect(
                    hostname=host,
                    port=port,
                    username=username,
                    pkey=private_key,
                    timeout=30,  # å¢åŠ åˆ°30ç§’
                    allow_agent=False,
                    look_for_keys=False
                )
            else:
                return False, f"ä¸æ”¯æŒçš„è®¤è¯æ–¹å¼: {auth_type}"

            print(f"âœ… SSHè¿æ¥å»ºç«‹æˆåŠŸ")

            # æµ‹è¯•æ‰§è¡Œç®€å•å‘½ä»¤
            print(f"ğŸ§ª æµ‹è¯•å‘½ä»¤æ‰§è¡Œ...")
            stdin, stdout, stderr = ssh.exec_command('echo "connection_test_$(date +%s)"', timeout=5)

            # è¯»å–è¾“å‡ºå’Œé”™è¯¯
            result = stdout.read().decode().strip()
            error_output = stderr.read().decode().strip()

            print(f"ğŸ“¤ å‘½ä»¤è¾“å‡º: '{result}'")
            if error_output:
                print(f"âš ï¸  é”™è¯¯è¾“å‡º: '{error_output}'")

            # éªŒè¯å‘½ä»¤æ‰§è¡Œç»“æœ
            if result and "connection_test_" in result:
                print(f"resultçš„ç»“æœæ˜¯: {result}")
                print(f"âœ… å‘½ä»¤æ‰§è¡ŒæˆåŠŸ")

                # é¢å¤–æµ‹è¯•ï¼šè·å–ç³»ç»Ÿä¿¡æ¯éªŒè¯æƒé™
                stdin2, stdout2, stderr2 = ssh.exec_command('whoami && uname -s', timeout=5)
                system_info = stdout2.read().decode().strip()
                print(f"ğŸ–¥ï¸  ç³»ç»Ÿä¿¡æ¯: {system_info}")

                ssh.close()
                return True, f"SSHè¿æ¥æµ‹è¯•æˆåŠŸ - ç”¨æˆ·: {system_info.split()[0] if system_info else username}"
            else:
                ssh.close()
                return False, f"SSHè¿æ¥æˆåŠŸä½†å‘½ä»¤æ‰§è¡Œå¤±è´¥ - è¾“å‡º: '{result}'"

        except paramiko.AuthenticationException as e:
            print(f"âŒ è®¤è¯å¤±è´¥: {e}")
            return False, f"SSHè®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç”¨æˆ·åå’Œå¯†ç /å¯†é’¥ - {str(e)}"
        except paramiko.SSHException as e:
            print(f"âŒ SSHé”™è¯¯: {e}")
            return False, f"SSHè¿æ¥é”™è¯¯: {str(e)}"
        except socket.timeout as e:
            print(f"âŒ è¿æ¥è¶…æ—¶: {e}")
            return False, f"è¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ä¸»æœºåœ°å€å’Œç«¯å£ - {str(e)}"
        except socket.gaierror as e:
            print(f"âŒ åŸŸåè§£æå¤±è´¥: {e}")
            return False, f"æ— æ³•è§£æä¸»æœºåï¼Œè¯·æ£€æŸ¥ä¸»æœºåœ°å€ - {str(e)}"
        except ConnectionRefusedError as e:
            print(f"âŒ è¿æ¥è¢«æ‹’ç»: {e}")
            return False, f"è¿æ¥è¢«æ‹’ç»ï¼Œè¯·æ£€æŸ¥SSHæœåŠ¡æ˜¯å¦è¿è¡Œå’Œç«¯å£æ˜¯å¦æ­£ç¡® - {str(e)}"
        except Exception as e:
            print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
            return False, f"è¿æ¥å¤±è´¥: {str(e)}"

    def get_real_server_metrics(self, server_config):
        """è·å–çœŸå®æœåŠ¡å™¨ç›‘æ§æ•°æ®"""
        if not PARAMIKO_AVAILABLE:
            return None

        try:
            host = server_config['host']
            port = server_config['port']
            username = server_config['username']
            auth_type = server_config.get('auth_type', 'password')

            # æœ¬åœ°æœåŠ¡å™¨ä½¿ç”¨psutil
            if host in ['localhost', '127.0.0.1'] or auth_type == 'local':
                return self._get_local_metrics()

            # è¿œç¨‹æœåŠ¡å™¨ä½¿ç”¨SSH
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())

            # è¿æ¥æœåŠ¡å™¨
            if auth_type == 'password':
                ssh.connect(
                    hostname=host,
                    port=port,
                    username=username,
                    password=server_config.get('password'),
                    timeout=30  # å¢åŠ åˆ°30ç§’
                )
            else:  # keyè®¤è¯
                private_key_path = server_config.get('private_key_path')
                key_password = server_config.get('key_password')

                try:
                    private_key = paramiko.RSAKey.from_private_key_file(private_key_path, password=key_password)
                except:
                    private_key = paramiko.Ed25519Key.from_private_key_file(private_key_path, password=key_password)

                ssh.connect(
                    hostname=host,
                    port=port,
                    username=username,
                    pkey=private_key,
                    timeout=30  # å¢åŠ åˆ°30ç§’
                )

            # è·å–ç³»ç»Ÿä¿¡æ¯
            metrics = {}

            # CPUä¿¡æ¯
            stdin, stdout, stderr = ssh.exec_command("top -bn1 | grep 'Cpu(s)' | awk '{print $2}' | cut -d'%' -f1")
            cpu_usage = stdout.read().decode().strip()
            try:
                metrics['cpu'] = float(cpu_usage)
            except:
                metrics['cpu'] = 0.0

            # è´Ÿè½½å¹³å‡å€¼
            stdin, stdout, stderr = ssh.exec_command("uptime | awk -F'load average:' '{print $2}' | awk '{print $1}' | tr -d ','")
            load_avg = stdout.read().decode().strip()
            try:
                metrics['load_avg'] = float(load_avg)
            except:
                metrics['load_avg'] = 0.0

            # å†…å­˜ä¿¡æ¯
            stdin, stdout, stderr = ssh.exec_command("free | grep Mem | awk '{printf \"%.1f %.1f\", $3/$2*100, $2/1024/1024}'")
            memory_info = stdout.read().decode().strip().split()
            try:
                metrics['memory_percent'] = float(memory_info[0])
                metrics['memory_total'] = float(memory_info[1])
                metrics['memory_used'] = metrics['memory_total'] * metrics['memory_percent'] / 100
            except:
                metrics['memory_percent'] = 0.0
                metrics['memory_total'] = 0.0
                metrics['memory_used'] = 0.0

            # ç£ç›˜ä¿¡æ¯
            stdin, stdout, stderr = ssh.exec_command("df -h / | tail -1 | awk '{print $5}' | tr -d '%'")
            disk_usage = stdout.read().decode().strip()
            try:
                metrics['disk_percent'] = float(disk_usage)
            except:
                metrics['disk_percent'] = 0.0

            stdin, stdout, stderr = ssh.exec_command("df -BG / | tail -1 | awk '{print $4}' | tr -d 'G'")
            disk_free = stdout.read().decode().strip()
            try:
                metrics['disk_free'] = float(disk_free)
            except:
                metrics['disk_free'] = 0.0

            # ç£ç›˜IOä¿¡æ¯ - ä½¿ç”¨iostatè·å–è¯»å†™é€Ÿåº¦
            stdin, stdout, stderr = ssh.exec_command("iostat -d 1 2 | tail -n +4 | grep -E '(vda|sda|nvme)' | tail -1 | awk '{print $3, $4}'")
            disk_io_info = stdout.read().decode().strip().split()
            try:
                if len(disk_io_info) >= 2:
                    # iostatè¾“å‡ºçš„æ˜¯kB/sï¼Œè½¬æ¢ä¸ºå­—èŠ‚/s
                    metrics['disk_read'] = float(disk_io_info[0]) * 1024  # kB/s -> B/s
                    metrics['disk_write'] = float(disk_io_info[1]) * 1024  # kB/s -> B/s
                else:
                    metrics['disk_read'] = 0.0
                    metrics['disk_write'] = 0.0
            except:
                metrics['disk_read'] = 0.0
                metrics['disk_write'] = 0.0

            # ç½‘ç»œä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆï¼‰
            stdin, stdout, stderr = ssh.exec_command("cat /proc/net/dev | grep -E '(eth0|ens|enp)' | head -1 | awk '{print $2, $10}'")
            network_info = stdout.read().decode().strip().split()
            try:
                metrics['network_recv'] = int(network_info[0]) if len(network_info) > 0 else 0
                metrics['network_sent'] = int(network_info[1]) if len(network_info) > 1 else 0
            except:
                metrics['network_recv'] = 0
                metrics['network_sent'] = 0

            ssh.close()
            return metrics

        except Exception as e:
            print(f"è·å–æœåŠ¡å™¨ç›‘æ§æ•°æ®å¤±è´¥: {e}")
            return None

    def _get_local_metrics(self):
        """è·å–æœ¬åœ°æœåŠ¡å™¨ç›‘æ§æ•°æ®"""
        try:
            import psutil

            metrics = {}

            # CPUä¿¡æ¯
            metrics['cpu'] = psutil.cpu_percent(interval=1)
            metrics['load_avg'] = psutil.getloadavg()[0] if hasattr(psutil, 'getloadavg') else 0.0

            # å†…å­˜ä¿¡æ¯
            memory = psutil.virtual_memory()
            metrics['memory_percent'] = memory.percent
            metrics['memory_total'] = memory.total / (1024**3)  # GB
            metrics['memory_used'] = memory.used / (1024**3)    # GB

            # ç£ç›˜ä¿¡æ¯
            disk = psutil.disk_usage('/')
            metrics['disk_percent'] = disk.percent
            metrics['disk_free'] = disk.free / (1024**3)  # GB

            # ç£ç›˜IOä¿¡æ¯
            disk_io = psutil.disk_io_counters()
            if disk_io:
                # è·å–å½“å‰æ—¶é—´æˆ³ï¼Œè®¡ç®—IOé€Ÿç‡
                current_time = time.time()
                if hasattr(self, '_last_disk_io') and hasattr(self, '_last_disk_time'):
                    time_diff = current_time - self._last_disk_time
                    if time_diff > 0:
                        read_diff = disk_io.read_bytes - self._last_disk_io.read_bytes
                        write_diff = disk_io.write_bytes - self._last_disk_io.write_bytes
                        metrics['disk_read'] = read_diff / time_diff  # bytes/s
                        metrics['disk_write'] = write_diff / time_diff  # bytes/s
                    else:
                        metrics['disk_read'] = 0.0
                        metrics['disk_write'] = 0.0
                else:
                    metrics['disk_read'] = 0.0
                    metrics['disk_write'] = 0.0

                # ä¿å­˜å½“å‰å€¼ç”¨äºä¸‹æ¬¡è®¡ç®—
                self._last_disk_io = disk_io
                self._last_disk_time = current_time
            else:
                metrics['disk_read'] = 0.0
                metrics['disk_write'] = 0.0

            # ç½‘ç»œä¿¡æ¯
            network = psutil.net_io_counters()
            metrics['network_recv'] = network.bytes_recv
            metrics['network_sent'] = network.bytes_sent

            return metrics

        except ImportError:
            print("psutilåº“æœªå®‰è£…ï¼Œæ— æ³•è·å–æœ¬åœ°ç›‘æ§æ•°æ®")
            return None
        except Exception as e:
            print(f"è·å–æœ¬åœ°ç›‘æ§æ•°æ®å¤±è´¥: {e}")
            return None

    def get_server_metrics(self, server_id, time_range='1h'):
        """ğŸš€ è·å–æœåŠ¡å™¨ç›‘æ§æ•°æ®ï¼ˆä½¿ç”¨ç¼“å­˜ä¼˜åŒ–ï¼‰"""
        if server_id not in self.servers:
            return None

        current_time = datetime.now()
        cache_key = f"{server_id}_metrics_{time_range}"

        print(f"ğŸ” æŸ¥æ‰¾ç¼“å­˜: {cache_key}")
        print(f"ğŸ“¦ å½“å‰ç¼“å­˜é”®: {list(self.performance_cache.keys())}")

        # ğŸ”¥ ä¼˜å…ˆä»ç¼“å­˜è·å–æ•°æ®
        if cache_key in self.performance_cache:
            cache_data = self.performance_cache[cache_key]
            cache_age = (current_time - cache_data['timestamp']).total_seconds()

            if cache_age < self.cache_ttl:
                print(f"âš¡ ä»ç¼“å­˜è·å–æ•°æ®: {server_id} ({cache_age:.1f}så‰)")

                # è·å–å®æ—¶æ•°æ®
                realtime_cache_key = f"{server_id}_realtime"
                current_metrics = None
                if realtime_cache_key in self.performance_cache:
                    current_metrics = self.performance_cache[realtime_cache_key]['data']

                if not current_metrics:
                    # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰å®æ—¶æ•°æ®ï¼Œå¿«é€Ÿè·å–
                    server_config = self.servers[server_id]
                    current_metrics = self.get_real_server_metrics(server_config)

                if not current_metrics:
                    return {
                        'error': 'æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨æˆ–è·å–ç›‘æ§æ•°æ®',
                        'suggestion': 'è¯·æ£€æŸ¥æœåŠ¡å™¨è¿æ¥çŠ¶æ€å’Œé…ç½®'
                    }

                # è·å–è¿›ç¨‹æ•°æ®ï¼ˆä¹Ÿå¯ä»¥ç¼“å­˜ï¼‰
                processes = self._get_real_processes(self.servers[server_id])

                return {
                    'current': current_metrics,
                    'historical': cache_data['data'],
                    'processes': processes,
                    'cache_info': {
                        'cache_hit': True,
                        'cache_age': f"{cache_age:.1f}s",
                        'last_update': current_time.strftime('%Y-%m-%d %H:%M:%S')
                    }
                }

        # ğŸŒ ç¼“å­˜æœªå‘½ä¸­ï¼Œè·å–æ–°æ•°æ®ï¼ˆè¿™ç§æƒ…å†µåº”è¯¥å¾ˆå°‘å‘ç”Ÿï¼Œå› ä¸ºåå°çº¿ç¨‹åœ¨æ›´æ–°ï¼‰
        print(f"ğŸ”„ ç¼“å­˜æœªå‘½ä¸­ï¼Œè·å–æ–°æ•°æ®: {server_id}")

        server_config = self.servers[server_id]
        real_metrics = self.get_real_server_metrics(server_config)

        if not real_metrics:
            return {
                'error': 'æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨æˆ–è·å–ç›‘æ§æ•°æ®',
                'suggestion': 'è¯·æ£€æŸ¥æœåŠ¡å™¨è¿æ¥çŠ¶æ€å’Œé…ç½®'
            }

        # è·å–å†å²æ•°æ®ï¼ˆé™åˆ¶æ•°æ®ç‚¹ï¼‰
        historical_data = self._get_cached_historical_data(server_id, time_range, real_metrics)

        # æ›´æ–°ç¼“å­˜
        self.performance_cache[cache_key] = {
            'data': historical_data,
            'timestamp': current_time,
            'ttl': self.cache_ttl
        }

        # è·å–è¿›ç¨‹æ•°æ®
        processes = self._get_real_processes(server_config)

        return {
            'current': real_metrics,
            'historical': historical_data,
            'processes': processes,
            'cache_info': {
                'cache_hit': False,
                'last_update': current_time.strftime('%Y-%m-%d %H:%M:%S')
            }
        }



    def _generate_historical_data(self, time_range, current_metrics, limit_points=False):
        """ç”Ÿæˆå†å²æ•°æ®ï¼ˆå¸¦ç¼“å­˜æœºåˆ¶å’Œæ•°æ®ç‚¹é™åˆ¶ï¼‰"""
        current_time = datetime.now()
        server_key = f"default_{time_range}"  # ç®€åŒ–çš„æœåŠ¡å™¨æ ‡è¯†

        # è§£ææ—¶é—´èŒƒå›´
        if time_range == '5m':
            duration_minutes = 5
            interval_seconds = 10
        elif time_range == '15m':
            duration_minutes = 15
            interval_seconds = 30
        elif time_range == '1h':
            duration_minutes = 60
            interval_seconds = 60
        elif time_range == '6h':
            duration_minutes = 360
            interval_seconds = 360
        elif time_range == '24h':
            duration_minutes = 1440
            interval_seconds = 1440
        else:
            duration_minutes = 60
            interval_seconds = 60

        points = duration_minutes * 60 // interval_seconds

        # ğŸš€ é™åˆ¶æ•°æ®ç‚¹æ•°é‡
        if limit_points and points > self.max_data_points:
            points = self.max_data_points
            interval_seconds = (duration_minutes * 60) // points
            print(f"ğŸ“Š é™åˆ¶æ•°æ®ç‚¹: {duration_minutes * 60 // interval_seconds} -> {points} ä¸ªç‚¹")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ç¼“å­˜
        if (server_key not in self.historical_cache or
            server_key not in self.last_update_time or
            (current_time - self.last_update_time[server_key]).total_seconds() > interval_seconds):

            print(f"ğŸ”„ æ›´æ–°å†å²æ•°æ®ç¼“å­˜: {server_key}")

            # è·å–æˆ–åˆå§‹åŒ–ç¼“å­˜
            if server_key not in self.historical_cache:
                self.historical_cache[server_key] = {
                    'data_points': [],
                    'max_points': points
                }

            cache = self.historical_cache[server_key]

            # æ·»åŠ æ–°çš„æ•°æ®ç‚¹ï¼ˆå½“å‰å®æ—¶æ•°æ®ï¼‰
            new_data_point = {
                'timestamp': current_time,
                'cpu': current_metrics.get('cpu', 0),
                'memory': current_metrics.get('memory_percent', 0),
                'disk_read': current_metrics.get('disk_read', 0),
                'disk_write': current_metrics.get('disk_write', 0),
                'network_sent': current_metrics.get('network_sent', 0),
                'network_recv': current_metrics.get('network_recv', 0)
            }

            cache['data_points'].append(new_data_point)

            # ä¿æŒæ•°æ®ç‚¹æ•°é‡ä¸è¶…è¿‡é™åˆ¶
            if len(cache['data_points']) > points:
                cache['data_points'] = cache['data_points'][-points:]

            # ä¸å†å¡«å……æ¨¡æ‹Ÿæ•°æ®ï¼Œåªä½¿ç”¨çœŸå®çš„ç›‘æ§æ•°æ®
            # å¦‚æœæ•°æ®ç‚¹ä¸å¤Ÿï¼Œå°±æ˜¾ç¤ºç°æœ‰çš„çœŸå®æ•°æ®ç‚¹
            print(f"ğŸ“Š å½“å‰çœŸå®æ•°æ®ç‚¹æ•°é‡: {len(cache['data_points'])}, è¯·æ±‚æ•°é‡: {points}")

            self.last_update_time[server_key] = current_time

        # ä»ç¼“å­˜æ„å»ºè¿”å›æ•°æ®
        cache = self.historical_cache[server_key]
        timestamps = []
        cpu_data = []
        memory_data = []
        disk_read_data = []
        disk_write_data = []
        network_sent_data = []
        network_recv_data = []

        for point in cache['data_points'][-points:]:  # å–æœ€æ–°çš„pointsä¸ªæ•°æ®ç‚¹
            timestamps.append(point['timestamp'].strftime('%H:%M:%S'))
            cpu_data.append(round(point['cpu'], 1))
            memory_data.append(round(point['memory'], 1))
            disk_read_data.append(int(point['disk_read']))
            disk_write_data.append(int(point['disk_write']))
            network_sent_data.append(int(point['network_sent']))
            network_recv_data.append(int(point['network_recv']))

        print(f"ğŸ“Š è¿”å›å†å²æ•°æ®: {len(cpu_data)}ä¸ªæ•°æ®ç‚¹, CPUèŒƒå›´: {min(cpu_data):.1f}-{max(cpu_data):.1f}%")

        result = {
            'timestamps': timestamps,
            'cpu': cpu_data,
            'memory': memory_data,
            'disk_read': disk_read_data,
            'disk_write': disk_write_data,
            'network_sent': network_sent_data,
            'network_recv': network_recv_data
        }

        # ä¿å­˜å†å²æ•°æ®åˆ°æ–‡ä»¶
        self.persistence.save_historical_data('default', result)

        return result



    def _get_real_processes(self, server_config):
        """è·å–çœŸå®è¿›ç¨‹æ•°æ®"""
        if not PARAMIKO_AVAILABLE:
            return []

        try:
            host = server_config['host']
            port = server_config['port']
            username = server_config['username']
            auth_type = server_config.get('auth_type', 'password')

            # æœ¬åœ°æœåŠ¡å™¨ä½¿ç”¨psutil
            if host in ['localhost', '127.0.0.1']:
                return self._get_local_processes()

            # è¿œç¨‹æœåŠ¡å™¨ä½¿ç”¨SSH
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())

            # è¿æ¥æœåŠ¡å™¨
            if auth_type == 'password':
                ssh.connect(
                    hostname=host,
                    port=port,
                    username=username,
                    password=server_config.get('password'),
                    timeout=30  # å¢åŠ åˆ°30ç§’
                )
            else:  # keyè®¤è¯
                private_key_path = server_config.get('private_key_path')
                key_password = server_config.get('key_password')

                try:
                    private_key = paramiko.RSAKey.from_private_key_file(private_key_path, password=key_password)
                except:
                    private_key = paramiko.Ed25519Key.from_private_key_file(private_key_path, password=key_password)

                ssh.connect(
                    hostname=host,
                    port=port,
                    username=username,
                    pkey=private_key,
                    timeout=30  # å¢åŠ åˆ°30ç§’
                )

            # è·å–è¿›ç¨‹ä¿¡æ¯ - æŒ‰CPUä½¿ç”¨ç‡æ’åºçš„å‰10ä¸ªè¿›ç¨‹
            cmd = "ps aux --sort=-%cpu | head -11 | tail -10 | awk '{print $2,$11,$3,$4,$8}'"
            print(f"ğŸ” æ‰§è¡Œè¿›ç¨‹æŸ¥è¯¢å‘½ä»¤: {cmd}")
            stdin, stdout, stderr = ssh.exec_command(cmd)
            process_lines = stdout.read().decode().strip().split('\n')
            error_output = stderr.read().decode().strip()

            print(f"ğŸ“Š è¿›ç¨‹å‘½ä»¤è¾“å‡ºè¡Œæ•°: {len(process_lines)}")
            print(f"ğŸ“Š è¿›ç¨‹åŸå§‹è¾“å‡º: {process_lines}")
            if error_output:
                print(f"âš ï¸ è¿›ç¨‹å‘½ä»¤é”™è¯¯è¾“å‡º: {error_output}")

            processes = []
            for i, line in enumerate(process_lines):
                if line.strip():
                    parts = line.strip().split(None, 4)
                    print(f"ğŸ“‹ è§£æç¬¬{i+1}è¡Œ: '{line}' -> åˆ†å‰²ä¸º {len(parts)} éƒ¨åˆ†: {parts}")
                    if len(parts) >= 5:
                        try:
                            process_data = {
                                'pid': int(parts[0]),
                                'name': parts[1].split('/')[-1][:20],  # åªå–ç¨‹åºåï¼Œé™åˆ¶é•¿åº¦
                                'cpu_percent': float(parts[2]),
                                'memory_percent': float(parts[3]),
                                'memory_mb': round(float(parts[3]) * 8 * 1024 / 100, 1),  # ä¼°ç®—å†…å­˜MB
                                'status': parts[4] if len(parts) > 4 else 'running',
                                'create_time': 'N/A'
                            }
                            processes.append(process_data)
                            print(f"âœ… æˆåŠŸè§£æè¿›ç¨‹: {process_data}")
                        except (ValueError, IndexError) as e:
                            print(f"âŒ è§£æè¿›ç¨‹å¤±è´¥: {e}, è¡Œå†…å®¹: '{line}'")
                            continue

            ssh.close()
            return processes[:10]  # è¿”å›å‰10ä¸ªè¿›ç¨‹

        except Exception as e:
            print(f"è·å–è¿›ç¨‹æ•°æ®å¤±è´¥: {e}")
            return []

    def _get_local_processes(self):
        """è·å–æœ¬åœ°è¿›ç¨‹æ•°æ®"""
        print("ğŸ” å¼€å§‹è·å–æœ¬åœ°è¿›ç¨‹æ•°æ®...")
        try:
            import psutil

            processes = []
            all_processes = list(psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent', 'memory_info', 'status', 'create_time']))
            print(f"ğŸ“Š ç³»ç»Ÿæ€»è¿›ç¨‹æ•°: {len(all_processes)}")

            for proc in all_processes:
                try:
                    pinfo = proc.info
                    # ç§»é™¤CPUä½¿ç”¨ç‡>0çš„é™åˆ¶ï¼Œè·å–æ‰€æœ‰è¿›ç¨‹
                    if pinfo['cpu_percent'] is not None:
                        process_data = {
                            'pid': pinfo['pid'],
                            'name': pinfo['name'][:20] if pinfo['name'] else 'Unknown',
                            'cpu_percent': round(pinfo['cpu_percent'], 1),
                            'memory_percent': round(pinfo['memory_percent'], 1) if pinfo['memory_percent'] else 0,
                            'memory_mb': round(pinfo['memory_info'].rss / 1024 / 1024, 1) if pinfo['memory_info'] else 0,
                            'status': pinfo['status'] if pinfo['status'] else 'unknown',
                            'create_time': datetime.fromtimestamp(pinfo['create_time']).strftime('%Y-%m-%d %H:%M:%S') if pinfo['create_time'] else 'N/A'
                        }
                        processes.append(process_data)
                except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
                    print(f"âš ï¸ æ— æ³•è®¿é—®è¿›ç¨‹: {e}")
                    continue

            print(f"ğŸ“Š æˆåŠŸè·å–è¿›ç¨‹æ•°: {len(processes)}")

            # æŒ‰CPUä½¿ç”¨ç‡æ’åºï¼Œè¿”å›å‰10ä¸ª
            sorted_processes = sorted(processes, key=lambda x: x['cpu_percent'], reverse=True)[:10]
            print(f"ğŸ“Š è¿”å›å‰10ä¸ªè¿›ç¨‹:")
            for i, proc in enumerate(sorted_processes):
                print(f"  {i+1}. PID:{proc['pid']} {proc['name']} CPU:{proc['cpu_percent']}% MEM:{proc['memory_percent']}%")

            return sorted_processes

        except ImportError:
            print("âŒ psutilåº“æœªå®‰è£…ï¼Œæ— æ³•è·å–æœ¬åœ°è¿›ç¨‹æ•°æ®")
            return []
        except Exception as e:
            print(f"âŒ è·å–æœ¬åœ°è¿›ç¨‹æ•°æ®å¤±è´¥: {e}")
            return []

# åˆ›å»ºæœåŠ¡å™¨ç›‘æ§å®ä¾‹
server_monitor = ServerMonitor()

# ä¸æ·»åŠ ä»»ä½•é»˜è®¤æœåŠ¡å™¨é…ç½®ï¼Œåªä½¿ç”¨ç”¨æˆ·çœŸå®æ·»åŠ çš„æœåŠ¡å™¨

@app.route('/api/analyze-monitoring-data', methods=['POST'])
def analyze_monitoring_data_api():
    """åˆ†æç›‘æ§æ•°æ®API"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰æä¾›æ•°æ®'})

        # åˆ†ææ•°æ®
        analysis_result = analyzer.analyze_monitoring_data(data)

        return jsonify({
            'success': True,
            'analysis': analysis_result
        })

    except Exception as e:
        return jsonify({'success': False, 'error': f'åˆ†ææ•°æ®æ—¶å‡ºé”™: {str(e)}'})

@app.route('/api/upload-monitoring-data', methods=['POST'])
def upload_monitoring_data():
    """ä¸Šä¼ ç›‘æ§æ•°æ®æ–‡ä»¶"""
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶'})

        file = request.files['file']
        if file.filename == '':
            return jsonify({'success': False, 'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'})

        if not file.filename.endswith('.json'):
            return jsonify({'success': False, 'error': 'åªæ”¯æŒJSONæ ¼å¼æ–‡ä»¶'})

        # è¯»å–æ–‡ä»¶å†…å®¹
        file_content = file.read().decode('utf-8')
        monitoring_data = json.loads(file_content)

        # åˆ†ææ•°æ®
        analysis_result = analyzer.analyze_monitoring_data(monitoring_data)

        # ä¿å­˜åˆ†æç»“æœï¼ˆå¯é€‰ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        result_filename = f"analysis_result_{timestamp}.json"

        return jsonify({
            'success': True,
            'analysis': analysis_result,
            'filename': file.filename
        })

    except json.JSONDecodeError:
        return jsonify({'success': False, 'error': 'JSONæ–‡ä»¶æ ¼å¼é”™è¯¯'})
    except Exception as e:
        return jsonify({'success': False, 'error': f'å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}'})

@app.route('/api/analyze-monitoring-data', methods=['POST'])
def analyze_monitoring_data():
    """åˆ†æç›‘æ§æ•°æ®ï¼ˆé€šè¿‡JSONæ•°æ®ï¼‰"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰æä¾›æ•°æ®'})

        # åˆ†ææ•°æ®
        analysis_result = analyzer.analyze_monitoring_data(data)

        return jsonify({
            'success': True,
            'analysis': analysis_result
        })

    except Exception as e:
        return jsonify({'success': False, 'error': f'åˆ†ææ•°æ®æ—¶å‡ºé”™: {str(e)}'})

# æœåŠ¡å™¨ç›‘æ§APIè·¯ç”±
@app.route('/api/servers', methods=['GET'])
def get_servers():
    """è·å–æœåŠ¡å™¨åˆ—è¡¨"""
    try:
        servers_list = list(server_monitor.servers.values())
        return jsonify({
            'success': True,
            'data': servers_list
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/servers', methods=['POST'])
def add_server():
    """æ·»åŠ æœåŠ¡å™¨"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰æä¾›æ•°æ®'})

        server_id = server_monitor.add_server(data)
        return jsonify({
            'success': True,
            'data': server_monitor.servers[server_id]
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/servers/<server_id>', methods=['PUT'])
def update_server(server_id):
    """æ›´æ–°æœåŠ¡å™¨é…ç½®"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰æä¾›æ•°æ®'})

        success = server_monitor.update_server(server_id, data)
        if success:
            return jsonify({
                'success': True,
                'data': server_monitor.servers[server_id]
            })
        else:
            return jsonify({'success': False, 'error': 'æœåŠ¡å™¨ä¸å­˜åœ¨'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/servers/<server_id>', methods=['DELETE'])
def delete_server(server_id):
    """åˆ é™¤æœåŠ¡å™¨"""
    try:
        success = server_monitor.delete_server(server_id)
        if success:
            return jsonify({'success': True})
        else:
            return jsonify({'success': False, 'error': 'æœåŠ¡å™¨ä¸å­˜åœ¨'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/servers/test', methods=['POST'])
@app.route('/api/servers/<server_id>/test', methods=['POST'])
def test_server_connection(server_id=None):
    """æµ‹è¯•æœåŠ¡å™¨è¿æ¥"""
    try:
        if server_id:
            # æµ‹è¯•å·²é…ç½®çš„æœåŠ¡å™¨
            if server_id not in server_monitor.servers:
                return jsonify({'success': False, 'error': 'æœåŠ¡å™¨ä¸å­˜åœ¨'})
            server_config = server_monitor.servers[server_id]
        else:
            # æµ‹è¯•æ–°çš„æœåŠ¡å™¨é…ç½®
            server_config = request.get_json()
            if not server_config:
                return jsonify({'success': False, 'error': 'æ²¡æœ‰æä¾›æœåŠ¡å™¨é…ç½®'})

        success, message = server_monitor.test_connection(server_config)
        return jsonify({
            'success': success,
            'message': message,
            'error': message if not success else None
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/servers/<server_id>/metrics', methods=['GET'])
def get_server_metrics_api(server_id):
    """è·å–æœåŠ¡å™¨ç›‘æ§æ•°æ®API"""
    try:
        if server_id not in server_monitor.servers:
            return jsonify({'success': False, 'error': 'æœåŠ¡å™¨ä¸å­˜åœ¨'})

        time_range = request.args.get('timeRange', '1h')
        print(f"ğŸ” APIè¯·æ±‚: {server_id}, æ—¶é—´èŒƒå›´: {time_range}")

        metrics_data = server_monitor.get_server_metrics(server_id, time_range)

        if metrics_data and 'error' not in metrics_data:
            return jsonify({
                'success': True,
                'data': metrics_data
            })
        elif metrics_data and 'error' in metrics_data:
            return jsonify({
                'success': False,
                'error': metrics_data['error'],
                'suggestion': metrics_data.get('suggestion', '')
            })
        else:
            return jsonify({'success': False, 'error': 'æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨è·å–ç›‘æ§æ•°æ®'})
    except Exception as e:
        print(f"âŒ APIé”™è¯¯: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/servers/<server_id>/metrics/realtime', methods=['GET'])
def get_server_realtime_metrics(server_id):
    """è·å–æœåŠ¡å™¨å®æ—¶æ•°æ®"""
    try:
        if server_id not in server_monitor.servers:
            return jsonify({'success': False, 'error': 'æœåŠ¡å™¨ä¸å­˜åœ¨'})

        # è·å–æœ€æ–°çš„ç›‘æ§æ•°æ®
        metrics_data = server_monitor.get_server_metrics(server_id, '5m')

        if metrics_data:
            return jsonify({
                'success': True,
                'data': metrics_data['current'],
                'timestamp': datetime.now().isoformat()
            })
        else:
            return jsonify({'success': False, 'error': 'è·å–å®æ—¶æ•°æ®å¤±è´¥'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/servers/<server_id>/processes', methods=['GET'])
def get_server_processes(server_id):
    """è·å–æœåŠ¡å™¨è¿›ç¨‹åˆ—è¡¨"""
    try:
        if server_id not in server_monitor.servers:
            return jsonify({'success': False, 'error': 'æœåŠ¡å™¨ä¸å­˜åœ¨'})

        limit = request.args.get('limit', 10, type=int)
        metrics_data = server_monitor.get_server_metrics(server_id, '5m')

        if metrics_data and 'processes' in metrics_data:
            processes = metrics_data['processes'][:limit]
            return jsonify({
                'success': True,
                'data': processes
            })
        else:
            return jsonify({'success': False, 'error': 'è·å–è¿›ç¨‹æ•°æ®å¤±è´¥'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/performance-monitor')
def performance_monitor():
    """æ€§èƒ½ç›‘æ§é¡µé¢"""
    html_template = '''
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ€§èƒ½ç›‘æ§åˆ†æ</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .header p {
            font-size: 1.1em;
            opacity: 0.9;
        }

        .upload-section {
            padding: 30px;
            background: #f8f9fa;
            border-bottom: 1px solid #e9ecef;
        }

        .upload-area {
            border: 3px dashed #007bff;
            border-radius: 10px;
            padding: 40px;
            text-align: center;
            background: white;
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .upload-area:hover {
            border-color: #0056b3;
            background: #f8f9ff;
        }

        .upload-area.dragover {
            border-color: #28a745;
            background: #f8fff8;
        }

        .upload-icon {
            font-size: 3em;
            color: #007bff;
            margin-bottom: 20px;
        }

        .btn {
            background: linear-gradient(135deg, #007bff 0%, #0056b3 100%);
            color: white;
            border: none;
            padding: 12px 30px;
            border-radius: 25px;
            cursor: pointer;
            font-size: 1em;
            transition: all 0.3s ease;
            margin: 10px;
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,123,255,0.3);
        }

        .analysis-section {
            padding: 30px;
            display: none;
        }

        .system-info {
            background: #e3f2fd;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 30px;
        }

        .performance-score {
            text-align: center;
            margin-bottom: 30px;
        }

        .score-circle {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            margin: 0 auto 20px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 2em;
            font-weight: bold;
            color: white;
        }

        .score-excellent { background: linear-gradient(135deg, #28a745, #20c997); }
        .score-good { background: linear-gradient(135deg, #ffc107, #fd7e14); }
        .score-poor { background: linear-gradient(135deg, #dc3545, #e83e8c); }

        .charts-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));
            gap: 30px;
            margin-bottom: 30px;
        }

        .chart-container {
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }

        .chart-title {
            font-size: 1.3em;
            font-weight: bold;
            margin-bottom: 20px;
            color: #2c3e50;
            text-align: center;
        }

        .bottlenecks-section {
            margin-top: 30px;
        }

        .bottleneck-item {
            background: white;
            border-left: 5px solid;
            padding: 20px;
            margin-bottom: 15px;
            border-radius: 0 10px 10px 0;
            box-shadow: 0 3px 10px rgba(0,0,0,0.1);
        }

        .bottleneck-critical { border-left-color: #dc3545; }
        .bottleneck-high { border-left-color: #fd7e14; }
        .bottleneck-medium { border-left-color: #ffc107; }

        .bottleneck-title {
            font-weight: bold;
            font-size: 1.1em;
            margin-bottom: 10px;
        }

        .bottleneck-description {
            color: #666;
            margin-bottom: 10px;
        }

        .bottleneck-impact {
            font-style: italic;
            color: #888;
        }

        .recommendations {
            background: #d4edda;
            border: 1px solid #c3e6cb;
            border-radius: 10px;
            padding: 20px;
            margin-top: 30px;
        }

        .recommendations h3 {
            color: #155724;
            margin-bottom: 15px;
        }

        .recommendation-item {
            background: white;
            padding: 15px;
            margin-bottom: 10px;
            border-radius: 5px;
            border-left: 4px solid #28a745;
        }

        .loading {
            text-align: center;
            padding: 50px;
        }

        .spinner {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #007bff;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            animation: spin 1s linear infinite;
            margin: 0 auto 20px;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .error-message {
            background: #f8d7da;
            color: #721c24;
            padding: 15px;
            border-radius: 5px;
            margin: 20px 0;
            border: 1px solid #f5c6cb;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸš€ æ€§èƒ½ç›‘æ§åˆ†æå¹³å°</h1>
            <p>ä¸Šä¼ ç³»ç»Ÿç›‘æ§æ•°æ®ï¼Œè·å–AIé©±åŠ¨çš„æ€§èƒ½ç“¶é¢ˆåˆ†æå’Œä¼˜åŒ–å»ºè®®</p>
        </div>

        <div class="upload-section">
            <div class="upload-area" id="uploadArea">
                <div class="upload-icon">ğŸ“</div>
                <h3>æ‹–æ‹½ç›‘æ§æ•°æ®æ–‡ä»¶åˆ°æ­¤å¤„</h3>
                <p>æˆ–è€…ç‚¹å‡»é€‰æ‹©æ–‡ä»¶</p>
                <p style="color: #666; margin-top: 10px;">æ”¯æŒ JSON æ ¼å¼çš„ç›‘æ§æ•°æ®æ–‡ä»¶</p>
                <input type="file" id="fileInput" accept=".json" style="display: none;">
                <button class="btn" onclick="document.getElementById('fileInput').click()">é€‰æ‹©æ–‡ä»¶</button>
            </div>
        </div>

        <div class="analysis-section" id="analysisSection">
            <!-- åˆ†æç»“æœå°†åœ¨è¿™é‡Œæ˜¾ç¤º -->
        </div>
    </div>

    <script>
        const uploadArea = document.getElementById('uploadArea');
        const fileInput = document.getElementById('fileInput');
        const analysisSection = document.getElementById('analysisSection');

        // æ‹–æ‹½ä¸Šä¼ åŠŸèƒ½
        uploadArea.addEventListener('dragover', (e) => {
            e.preventDefault();
            uploadArea.classList.add('dragover');
        });

        uploadArea.addEventListener('dragleave', () => {
            uploadArea.classList.remove('dragover');
        });

        uploadArea.addEventListener('drop', (e) => {
            e.preventDefault();
            uploadArea.classList.remove('dragover');
            const files = e.dataTransfer.files;
            if (files.length > 0) {
                handleFile(files[0]);
            }
        });

        fileInput.addEventListener('change', (e) => {
            if (e.target.files.length > 0) {
                handleFile(e.target.files[0]);
            }
        });

        function handleFile(file) {
            if (!file.name.endsWith('.json')) {
                showError('è¯·é€‰æ‹©JSONæ ¼å¼çš„ç›‘æ§æ•°æ®æ–‡ä»¶');
                return;
            }

            showLoading();

            const formData = new FormData();
            formData.append('file', file);

            fetch('/api/upload-monitoring-data', {
                method: 'POST',
                body: formData
            })
            .then(response => response.json())
            .then(data => {
                if (data.success) {
                    displayAnalysis(data.analysis);
                } else {
                    showError(data.error);
                }
            })
            .catch(error => {
                showError('ä¸Šä¼ æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: ' + error.message);
            });
        }

        function showLoading() {
            analysisSection.style.display = 'block';
            analysisSection.innerHTML = `
                <div class="loading">
                    <div class="spinner"></div>
                    <h3>æ­£åœ¨åˆ†æç›‘æ§æ•°æ®...</h3>
                    <p>AIæ­£åœ¨è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå’Œä¼˜åŒ–æœºä¼š</p>
                </div>
            `;
        }

        function showError(message) {
            analysisSection.style.display = 'block';
            analysisSection.innerHTML = `
                <div class="error-message">
                    <strong>é”™è¯¯:</strong> ${message}
                </div>
            `;
        }

        function displayAnalysis(analysis) {
            const systemInfo = analysis.system_info;
            const score = analysis.performance_score;
            const bottlenecks = analysis.bottlenecks;
            const recommendations = analysis.recommendations;
            const chartsData = analysis.charts_data;

            let scoreClass = 'score-excellent';
            let scoreText = 'ä¼˜ç§€';
            if (score < 70) {
                scoreClass = 'score-poor';
                scoreText = 'éœ€è¦ä¼˜åŒ–';
            } else if (score < 85) {
                scoreClass = 'score-good';
                scoreText = 'è‰¯å¥½';
            }

            analysisSection.innerHTML = `
                <div class="system-info">
                    <h2>ğŸ“Š ç³»ç»Ÿä¿¡æ¯</h2>
                    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin-top: 15px;">
                        <div><strong>ä¸»æœºå:</strong> ${systemInfo.hostname}</div>
                        <div><strong>ç³»ç»Ÿ:</strong> ${systemInfo.system} ${systemInfo.release}</div>
                        <div><strong>CPU:</strong> ${systemInfo.cpu_model || 'Unknown'}</div>
                        <div><strong>CPUæ ¸å¿ƒ:</strong> ${systemInfo.cpu_count_logical}ä¸ªé€»è¾‘æ ¸å¿ƒ</div>
                        <div><strong>æ€»å†…å­˜:</strong> ${systemInfo.total_memory_gb}GB</div>
                        <div><strong>ç›‘æ§æ—¶é•¿:</strong> ${analysis.monitoring_summary.duration_seconds}ç§’</div>
                    </div>
                </div>

                <div class="performance-score">
                    <h2>ğŸ¯ æ€§èƒ½è¯„åˆ†</h2>
                    <div class="score-circle ${scoreClass}">
                        ${score}
                    </div>
                    <h3>${scoreText}</h3>
                </div>

                <div class="charts-grid">
                    <div class="chart-container">
                        <div class="chart-title">CPUä½¿ç”¨ç‡è¶‹åŠ¿</div>
                        <canvas id="cpuChart"></canvas>
                    </div>
                    <div class="chart-container">
                        <div class="chart-title">å†…å­˜ä½¿ç”¨ç‡è¶‹åŠ¿</div>
                        <canvas id="memoryChart"></canvas>
                    </div>
                    <div class="chart-container">
                        <div class="chart-title">ç³»ç»Ÿè´Ÿè½½è¶‹åŠ¿</div>
                        <canvas id="loadChart"></canvas>
                    </div>
                    <div class="chart-container">
                        <div class="chart-title">CPUæ ¸å¿ƒä½¿ç”¨ç‡</div>
                        <canvas id="coreChart"></canvas>
                    </div>
                </div>

                <div class="bottlenecks-section">
                    <h2>âš ï¸ æ€§èƒ½ç“¶é¢ˆåˆ†æ</h2>
                    ${bottlenecks.length > 0 ?
                        bottlenecks.map(bottleneck => `
                            <div class="bottleneck-item bottleneck-${bottleneck.severity}">
                                <div class="bottleneck-title">${getBottleneckIcon(bottleneck.severity)} ${bottleneck.description}</div>
                                <div class="bottleneck-impact">å½±å“: ${bottleneck.impact}</div>
                            </div>
                        `).join('') :
                        '<div style="text-align: center; padding: 40px; color: #28a745;"><h3>ğŸ‰ æœªå‘ç°æ˜æ˜¾çš„æ€§èƒ½ç“¶é¢ˆ</h3><p>ç³»ç»Ÿè¿è¡ŒçŠ¶å†µè‰¯å¥½</p></div>'
                    }
                </div>

                ${recommendations.length > 0 ? `
                    <div class="recommendations">
                        <h3>ğŸ’¡ ä¼˜åŒ–å»ºè®®</h3>
                        ${recommendations.map((rec, index) => `
                            <div class="recommendation-item">
                                ${index + 1}. ${rec}
                            </div>
                        `).join('')}
                    </div>
                ` : ''}
            `;

            // ç»˜åˆ¶å›¾è¡¨
            setTimeout(() => {
                drawCharts(chartsData);
            }, 100);
        }

        function getBottleneckIcon(severity) {
            switch(severity) {
                case 'critical': return 'ğŸ”´';
                case 'high': return 'ğŸŸ ';
                case 'medium': return 'ğŸŸ¡';
                default: return 'ğŸ”µ';
            }
        }

        function drawCharts(chartsData) {
            // CPUä½¿ç”¨ç‡å›¾è¡¨
            if (chartsData.cpu_timeline.length > 0) {
                const cpuCtx = document.getElementById('cpuChart').getContext('2d');
                new Chart(cpuCtx, {
                    type: 'line',
                    data: {
                        labels: chartsData.cpu_timeline.map(item => new Date(item.time).toLocaleTimeString()),
                        datasets: [{
                            label: 'CPUä½¿ç”¨ç‡ (%)',
                            data: chartsData.cpu_timeline.map(item => item.cpu_percent),
                            borderColor: '#007bff',
                            backgroundColor: 'rgba(0, 123, 255, 0.1)',
                            tension: 0.4
                        }]
                    },
                    options: {
                        responsive: true,
                        scales: {
                            y: {
                                beginAtZero: true,
                                max: 100
                            }
                        }
                    }
                });
            }

            // å†…å­˜ä½¿ç”¨ç‡å›¾è¡¨
            if (chartsData.memory_timeline.length > 0) {
                const memoryCtx = document.getElementById('memoryChart').getContext('2d');
                new Chart(memoryCtx, {
                    type: 'line',
                    data: {
                        labels: chartsData.memory_timeline.map(item => new Date(item.time).toLocaleTimeString()),
                        datasets: [{
                            label: 'å†…å­˜ä½¿ç”¨ç‡ (%)',
                            data: chartsData.memory_timeline.map(item => item.memory_percent),
                            borderColor: '#28a745',
                            backgroundColor: 'rgba(40, 167, 69, 0.1)',
                            tension: 0.4
                        }, {
                            label: 'äº¤æ¢åˆ†åŒºä½¿ç”¨ç‡ (%)',
                            data: chartsData.memory_timeline.map(item => item.swap_percent),
                            borderColor: '#dc3545',
                            backgroundColor: 'rgba(220, 53, 69, 0.1)',
                            tension: 0.4
                        }]
                    },
                    options: {
                        responsive: true,
                        scales: {
                            y: {
                                beginAtZero: true,
                                max: 100
                            }
                        }
                    }
                });
            }

            // ç³»ç»Ÿè´Ÿè½½å›¾è¡¨
            if (chartsData.cpu_timeline.length > 0) {
                const loadCtx = document.getElementById('loadChart').getContext('2d');
                new Chart(loadCtx, {
                    type: 'line',
                    data: {
                        labels: chartsData.cpu_timeline.map(item => new Date(item.time).toLocaleTimeString()),
                        datasets: [{
                            label: '1åˆ†é’Ÿè´Ÿè½½å¹³å‡å€¼',
                            data: chartsData.cpu_timeline.map(item => item.load_1min),
                            borderColor: '#ffc107',
                            backgroundColor: 'rgba(255, 193, 7, 0.1)',
                            tension: 0.4
                        }]
                    },
                    options: {
                        responsive: true,
                        scales: {
                            y: {
                                beginAtZero: true
                            }
                        }
                    }
                });
            }

            // CPUæ ¸å¿ƒä½¿ç”¨ç‡å›¾è¡¨
            if (chartsData.cpu_cores.length > 0) {
                const coreCtx = document.getElementById('coreChart').getContext('2d');
                new Chart(coreCtx, {
                    type: 'bar',
                    data: {
                        labels: chartsData.cpu_cores.map(item => item.core),
                        datasets: [{
                            label: 'CPUæ ¸å¿ƒä½¿ç”¨ç‡ (%)',
                            data: chartsData.cpu_cores.map(item => item.usage),
                            backgroundColor: chartsData.cpu_cores.map(item =>
                                item.usage > 80 ? '#dc3545' :
                                item.usage > 60 ? '#ffc107' : '#28a745'
                            )
                        }]
                    },
                    options: {
                        responsive: true,
                        scales: {
                            y: {
                                beginAtZero: true,
                                max: 100
                            }
                        }
                    }
                });
            }
        }
    </script>
</body>
</html>
    '''
    return render_template_string(html_template)

if __name__ == '__main__':
    print('å¯åŠ¨Pythonä»£ç æ‰§è¡ŒæœåŠ¡...')
    print('è®¿é—® http://localhost:5000/api/health æ£€æŸ¥æœåŠ¡çŠ¶æ€')
    print('æœåŠ¡æ­£åœ¨å¯åŠ¨...')
    try:
        app.run(host='0.0.0.0', port=5000, debug=False)
    except Exception as e:
        print(f'å¯åŠ¨å¤±è´¥: {e}')
